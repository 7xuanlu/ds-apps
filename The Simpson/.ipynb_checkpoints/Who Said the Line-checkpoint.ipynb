{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who Said the Line in Simpson's TV Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils.extmath import density\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import TC algorithms\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8084: expected 13 fields, saw 20\\nSkipping line 52607: expected 13 fields, saw 21\\nSkipping line 59910: expected 13 fields, saw 21\\n'\n",
      "b'Skipping line 71801: expected 13 fields, saw 20\\nSkipping line 73539: expected 13 fields, saw 21\\nSkipping line 77230: expected 13 fields, saw 21\\nSkipping line 78953: expected 13 fields, saw 21\\nSkipping line 81138: expected 13 fields, saw 20\\nSkipping line 86746: expected 13 fields, saw 22\\nSkipping line 101154: expected 13 fields, saw 21\\nSkipping line 115438: expected 13 fields, saw 20\\nSkipping line 117573: expected 13 fields, saw 22\\nSkipping line 130610: expected 13 fields, saw 22\\n'\n",
      "b'Skipping line 152970: expected 13 fields, saw 22\\nSkipping line 153017: expected 13 fields, saw 20\\nSkipping line 153018: expected 13 fields, saw 30\\nSkipping line 154080: expected 13 fields, saw 20\\nSkipping line 154082: expected 13 fields, saw 20\\nSkipping line 154084: expected 13 fields, saw 20\\nSkipping line 154086: expected 13 fields, saw 20\\nSkipping line 154089: expected 13 fields, saw 23\\nSkipping line 154165: expected 13 fields, saw 21\\nSkipping line 156872: expected 13 fields, saw 20\\n'\n",
      "C:\\Users\\h164654156465\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "script_df = pd.read_csv('simpsons_script_lines.csv', error_bad_lines=False)\n",
    "char_df = pd.read_csv('simpsons_characters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simple Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>number</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>timestamp_in_ms</th>\n",
       "      <th>speaking_line</th>\n",
       "      <th>character_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>raw_location_text</th>\n",
       "      <th>spoken_words</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9549</td>\n",
       "      <td>32</td>\n",
       "      <td>209</td>\n",
       "      <td>Miss Hoover: No, actually, it was a little of ...</td>\n",
       "      <td>848000</td>\n",
       "      <td>True</td>\n",
       "      <td>464</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "      <td>no actually it was a little of both sometimes ...</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9550</td>\n",
       "      <td>32</td>\n",
       "      <td>210</td>\n",
       "      <td>Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?</td>\n",
       "      <td>856000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "      <td>wheres mr bergstrom</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9551</td>\n",
       "      <td>32</td>\n",
       "      <td>211</td>\n",
       "      <td>Miss Hoover: I don't know. Although I'd sure l...</td>\n",
       "      <td>856000</td>\n",
       "      <td>True</td>\n",
       "      <td>464</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "      <td>i dont know although id sure like to talk to h...</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9552</td>\n",
       "      <td>32</td>\n",
       "      <td>212</td>\n",
       "      <td>Lisa Simpson: That life is worth living.</td>\n",
       "      <td>864000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>That life is worth living.</td>\n",
       "      <td>that life is worth living</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9553</td>\n",
       "      <td>32</td>\n",
       "      <td>213</td>\n",
       "      <td>Edna Krabappel-Flanders: The polls will be ope...</td>\n",
       "      <td>864000</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "      <td>the polls will be open from now until the end ...</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  episode_id  number  \\\n",
       "0  9549          32     209   \n",
       "1  9550          32     210   \n",
       "2  9551          32     211   \n",
       "3  9552          32     212   \n",
       "4  9553          32     213   \n",
       "\n",
       "                                            raw_text timestamp_in_ms  \\\n",
       "0  Miss Hoover: No, actually, it was a little of ...          848000   \n",
       "1  Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?          856000   \n",
       "2  Miss Hoover: I don't know. Although I'd sure l...          856000   \n",
       "3           Lisa Simpson: That life is worth living.          864000   \n",
       "4  Edna Krabappel-Flanders: The polls will be ope...          864000   \n",
       "\n",
       "  speaking_line character_id  location_id       raw_character_text  \\\n",
       "0          True          464          3.0              Miss Hoover   \n",
       "1          True            9          3.0             Lisa Simpson   \n",
       "2          True          464          3.0              Miss Hoover   \n",
       "3          True            9          3.0             Lisa Simpson   \n",
       "4          True           40          3.0  Edna Krabappel-Flanders   \n",
       "\n",
       "               raw_location_text  \\\n",
       "0  Springfield Elementary School   \n",
       "1  Springfield Elementary School   \n",
       "2  Springfield Elementary School   \n",
       "3  Springfield Elementary School   \n",
       "4  Springfield Elementary School   \n",
       "\n",
       "                                        spoken_words  \\\n",
       "0  No, actually, it was a little of both. Sometim...   \n",
       "1                             Where's Mr. Bergstrom?   \n",
       "2  I don't know. Although I'd sure like to talk t...   \n",
       "3                         That life is worth living.   \n",
       "4  The polls will be open from now until the end ...   \n",
       "\n",
       "                                     normalized_text  word_count  \n",
       "0  no actually it was a little of both sometimes ...        31.0  \n",
       "1                                wheres mr bergstrom         3.0  \n",
       "2  i dont know although id sure like to talk to h...        22.0  \n",
       "3                          that life is worth living         5.0  \n",
       "4  the polls will be open from now until the end ...        33.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>normalized_name</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Children</td>\n",
       "      <td>children</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>Mechanical Santa</td>\n",
       "      <td>mechanical santa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Tattoo Man</td>\n",
       "      <td>tattoo man</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>DOCTOR ZITSOFSKY</td>\n",
       "      <td>doctor zitsofsky</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>Students</td>\n",
       "      <td>students</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id              name   normalized_name gender\n",
       "0   7          Children          children    NaN\n",
       "1  12  Mechanical Santa  mechanical santa    NaN\n",
       "2  13        Tattoo Man        tattoo man    NaN\n",
       "3  16  DOCTOR ZITSOFSKY  doctor zitsofsky    NaN\n",
       "4  20          Students          students    NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We just need dialogue and character to do text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_id</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>464</td>\n",
       "      <td>no actually it was a little of both sometimes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>wheres mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>464</td>\n",
       "      <td>i dont know although id sure like to talk to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>that life is worth living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>the polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character_id                                    normalized_text\n",
       "0          464  no actually it was a little of both sometimes ...\n",
       "1            9                                wheres mr bergstrom\n",
       "2          464  i dont know although id sure like to talk to h...\n",
       "3            9                          that life is worth living\n",
       "4           40  the polls will be open from now until the end ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dial_df = (\n",
    "    script_df.dropna()\n",
    "    .loc[script_df['speaking_line'] == True]\n",
    "    [['character_id', 'normalized_text']]\n",
    ")\n",
    "dial_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We wanna know the top 14 characters who speaked the most among all the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>23011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>71.0</td>\n",
       "      <td>1622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>139.0</td>\n",
       "      <td>1478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>101.0</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>165.0</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  occurrence\n",
       "0     2.0       23011\n",
       "1     1.0       10750\n",
       "2     8.0       10591\n",
       "3     9.0        9078\n",
       "4    15.0        2498\n",
       "5    17.0        2342\n",
       "6     3.0        2044\n",
       "7    11.0        1793\n",
       "8    71.0        1622\n",
       "9    25.0        1480\n",
       "10  139.0        1478\n",
       "11   31.0        1413\n",
       "12  101.0        1022\n",
       "13  165.0         940"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = dial_df['character_id'].value_counts()\n",
    "count = count.to_frame()\n",
    "count = count.reset_index()\n",
    "count.rename(columns={'index':'id', 'character_id':'occurrence'}, inplace=True)\n",
    "#count['id'] = count['id'].apply(int)\n",
    "count.head(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given the character list in the DS & ML class, we create our own one to compare with it.\n",
    "Here is the list below:\n",
    "1. Homer Simpson\n",
    "2. Marge Simpson\n",
    "3. Bart Simpson\n",
    "4. Lisa Simpson\n",
    "5. C. Montgomery Burns\n",
    "6. Moe Szyslak\n",
    "7. Seymour Skinner\n",
    "8. Ned Flanders\n",
    "9. Grampa Simpson\n",
    "10. Chief Wiggum\n",
    "11. Milhouse Van Houten\n",
    "12. Krusty the Clown\n",
    "13. Nelson Muntz\n",
    "14. Lenny Leonard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>2</td>\n",
       "      <td>Homer Simpson</td>\n",
       "      <td>23011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>Marge Simpson</td>\n",
       "      <td>10750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>Bart Simpson</td>\n",
       "      <td>10591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>9078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5301</th>\n",
       "      <td>15</td>\n",
       "      <td>C. Montgomery Burns</td>\n",
       "      <td>2498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>17</td>\n",
       "      <td>Moe Szyslak</td>\n",
       "      <td>2342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>Seymour Skinner</td>\n",
       "      <td>2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>11</td>\n",
       "      <td>Ned Flanders</td>\n",
       "      <td>1793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>71</td>\n",
       "      <td>Chief Wiggum</td>\n",
       "      <td>1622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>25</td>\n",
       "      <td>Milhouse Van Houten</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>139</td>\n",
       "      <td>Krusty the Clown</td>\n",
       "      <td>1478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>31</td>\n",
       "      <td>Grampa Simpson</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>101</td>\n",
       "      <td>Nelson Muntz</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>165</td>\n",
       "      <td>Lenny Leonard</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                 name  occurrence\n",
       "5300    2        Homer Simpson       23011\n",
       "27      1        Marge Simpson       10750\n",
       "28      8         Bart Simpson       10591\n",
       "29      9         Lisa Simpson        9078\n",
       "5301   15  C. Montgomery Burns        2498\n",
       "30     17          Moe Szyslak        2342\n",
       "31      3      Seymour Skinner        2044\n",
       "32     11         Ned Flanders        1793\n",
       "34     71         Chief Wiggum        1622\n",
       "35     25  Milhouse Van Houten        1480\n",
       "5302  139     Krusty the Clown        1478\n",
       "33     31       Grampa Simpson        1413\n",
       "37    101         Nelson Muntz        1022\n",
       "94    165        Lenny Leonard         940"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.merge(char_df[['id', 'name']], count, on='id')\n",
    "result = result.sort_values('occurrence', ascending=False)\n",
    "result.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_id</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>never thrown a party what about that big bash ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>lisa tell your fatherhomer you are not allowed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>victory party under the slidehey thanks for yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>wheres mr bergstromthat life is worth livingmr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>must turn over got to greet dignitariesabsolut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.0</td>\n",
       "      <td>college boymoes tavern where the elite meet to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>dont worry bart well find something fun for yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.0</td>\n",
       "      <td>hey anybody mind if i serve as bartender you k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>71.0</td>\n",
       "      <td>hellowell its about time somebody reach out to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25.0</td>\n",
       "      <td>uh ohwhat about you bart didnt you votebarts j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>139.0</td>\n",
       "      <td>hi kids youve reached the krusty hotline if yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31.0</td>\n",
       "      <td>huh who whati can dress myselfoh sure last res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>101.0</td>\n",
       "      <td>i didnt vote votings for geekshaw haw hawyeahh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>165.0</td>\n",
       "      <td>whats thathey homer we saved you a doughnuthey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>208.0</td>\n",
       "      <td>ooh very good would you like the deposit defra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.0</td>\n",
       "      <td>mr burns is never late something must be terri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>211.0</td>\n",
       "      <td>and the guy in the pink shirt is the father of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>170.0</td>\n",
       "      <td>id give him my blood except for one thingi don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>40.0</td>\n",
       "      <td>the polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>332.0</td>\n",
       "      <td>uh no not really someone seems to have slipped...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>18.0</td>\n",
       "      <td>hi youre homers sister-in-law right i remember...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>i owe you a lunchuh-huh in a secondnow henry w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>240.0</td>\n",
       "      <td>ah chief wiggum archbishop mcgee distinguished...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>140.0</td>\n",
       "      <td>now before i give you all a sneak preview of n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>153.0</td>\n",
       "      <td>selma dear im afraid the childrens reaction is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>404.0</td>\n",
       "      <td>i thought i found him but it was only a catwil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>119.0</td>\n",
       "      <td>im gonna eat chocolate till i barfyes but what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1078.0</td>\n",
       "      <td>hello seymourwere dropping the geography requi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>801.0</td>\n",
       "      <td>check it out spinal tap kicking mo-mar kadaffy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>52.0</td>\n",
       "      <td>tell my friends all right but ive got some pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326</th>\n",
       "      <td>4264.0</td>\n",
       "      <td>mr simpson for a loan this big youll have to p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5327</th>\n",
       "      <td>4266.0</td>\n",
       "      <td>i dont wanna be a three i wanna be a seven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5328</th>\n",
       "      <td>2161.0</td>\n",
       "      <td>betty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5329</th>\n",
       "      <td>4267.0</td>\n",
       "      <td>shut up kid youre as crazy as an eight im tell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5330</th>\n",
       "      <td>4268.0</td>\n",
       "      <td>you dont understand officer i thought that kin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5331</th>\n",
       "      <td>4269.0</td>\n",
       "      <td>hey jack got any twos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5332</th>\n",
       "      <td>2157.0</td>\n",
       "      <td>i was jush happy to see so many nice people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5333</th>\n",
       "      <td>4270.0</td>\n",
       "      <td>you cant handle the twos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5334</th>\n",
       "      <td>4271.0</td>\n",
       "      <td>youre the boss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5335</th>\n",
       "      <td>2172.0</td>\n",
       "      <td>um wh-wh-what do you mean exactly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5336</th>\n",
       "      <td>4252.0</td>\n",
       "      <td>thats a good one johnny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5337</th>\n",
       "      <td>2174.0</td>\n",
       "      <td>we were eating rotisserie chicken can you just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>4245.0</td>\n",
       "      <td>mr retailer -- over here your customers will l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5339</th>\n",
       "      <td>2197.0</td>\n",
       "      <td>good evening there miss heres yer giant sub sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5340</th>\n",
       "      <td>2196.0</td>\n",
       "      <td>hey this isnt faux dive this is a dive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5341</th>\n",
       "      <td>2193.0</td>\n",
       "      <td>geech gone to heaven mr terwillidjer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5342</th>\n",
       "      <td>4239.0</td>\n",
       "      <td>how male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5343</th>\n",
       "      <td>4241.0</td>\n",
       "      <td>screw her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5344</th>\n",
       "      <td>4244.0</td>\n",
       "      <td>oh my god its a small retailer he could make o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5345</th>\n",
       "      <td>2188.0</td>\n",
       "      <td>i hope they still make that shampoo i like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5346</th>\n",
       "      <td>2184.0</td>\n",
       "      <td>oh be nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5347</th>\n",
       "      <td>2175.0</td>\n",
       "      <td>okay homer lets get a level check on your voice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5348</th>\n",
       "      <td>2183.0</td>\n",
       "      <td>hot stuff comin through</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5349</th>\n",
       "      <td>2182.0</td>\n",
       "      <td>hel-lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5350</th>\n",
       "      <td>2181.0</td>\n",
       "      <td>uh no but we do have some old shirt buttons th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5351</th>\n",
       "      <td>4248.0</td>\n",
       "      <td>dont hold my hand its creepy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5352</th>\n",
       "      <td>4249.0</td>\n",
       "      <td>hm what to do what to do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5353</th>\n",
       "      <td>2177.0</td>\n",
       "      <td>in episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5354</th>\n",
       "      <td>4251.0</td>\n",
       "      <td>splendid welcome to canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5355</th>\n",
       "      <td>6086.0</td>\n",
       "      <td>welcome to eight days and seven nights of push...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5356 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      character_id                                    normalized_text\n",
       "0              2.0  never thrown a party what about that big bash ...\n",
       "1              1.0  lisa tell your fatherhomer you are not allowed...\n",
       "2              8.0  victory party under the slidehey thanks for yo...\n",
       "3              9.0  wheres mr bergstromthat life is worth livingmr...\n",
       "4             15.0  must turn over got to greet dignitariesabsolut...\n",
       "5             17.0  college boymoes tavern where the elite meet to...\n",
       "6              3.0  dont worry bart well find something fun for yo...\n",
       "7             11.0  hey anybody mind if i serve as bartender you k...\n",
       "8             71.0  hellowell its about time somebody reach out to...\n",
       "9             25.0  uh ohwhat about you bart didnt you votebarts j...\n",
       "10           139.0  hi kids youve reached the krusty hotline if yo...\n",
       "11            31.0  huh who whati can dress myselfoh sure last res...\n",
       "12           101.0  i didnt vote votings for geekshaw haw hawyeahh...\n",
       "13           165.0  whats thathey homer we saved you a doughnuthey...\n",
       "14           208.0  ooh very good would you like the deposit defra...\n",
       "15            14.0  mr burns is never late something must be terri...\n",
       "16           211.0  and the guy in the pink shirt is the father of...\n",
       "17           170.0  id give him my blood except for one thingi don...\n",
       "18            40.0  the polls will be open from now until the end ...\n",
       "19           332.0  uh no not really someone seems to have slipped...\n",
       "20            18.0  hi youre homers sister-in-law right i remember...\n",
       "21            22.0  i owe you a lunchuh-huh in a secondnow henry w...\n",
       "22           240.0  ah chief wiggum archbishop mcgee distinguished...\n",
       "23           140.0  now before i give you all a sneak preview of n...\n",
       "24           153.0  selma dear im afraid the childrens reaction is...\n",
       "25           404.0  i thought i found him but it was only a catwil...\n",
       "26           119.0  im gonna eat chocolate till i barfyes but what...\n",
       "27          1078.0  hello seymourwere dropping the geography requi...\n",
       "28           801.0  check it out spinal tap kicking mo-mar kadaffy...\n",
       "29            52.0  tell my friends all right but ive got some pre...\n",
       "...            ...                                                ...\n",
       "5326        4264.0  mr simpson for a loan this big youll have to p...\n",
       "5327        4266.0         i dont wanna be a three i wanna be a seven\n",
       "5328        2161.0                                              betty\n",
       "5329        4267.0  shut up kid youre as crazy as an eight im tell...\n",
       "5330        4268.0  you dont understand officer i thought that kin...\n",
       "5331        4269.0                              hey jack got any twos\n",
       "5332        2157.0        i was jush happy to see so many nice people\n",
       "5333        4270.0                           you cant handle the twos\n",
       "5334        4271.0                                     youre the boss\n",
       "5335        2172.0                  um wh-wh-what do you mean exactly\n",
       "5336        4252.0                            thats a good one johnny\n",
       "5337        2174.0  we were eating rotisserie chicken can you just...\n",
       "5338        4245.0  mr retailer -- over here your customers will l...\n",
       "5339        2197.0  good evening there miss heres yer giant sub sw...\n",
       "5340        2196.0             hey this isnt faux dive this is a dive\n",
       "5341        2193.0               geech gone to heaven mr terwillidjer\n",
       "5342        4239.0                                           how male\n",
       "5343        4241.0                                          screw her\n",
       "5344        4244.0  oh my god its a small retailer he could make o...\n",
       "5345        2188.0         i hope they still make that shampoo i like\n",
       "5346        2184.0                                         oh be nice\n",
       "5347        2175.0    okay homer lets get a level check on your voice\n",
       "5348        2183.0                            hot stuff comin through\n",
       "5349        2182.0                                             hel-lo\n",
       "5350        2181.0  uh no but we do have some old shirt buttons th...\n",
       "5351        4248.0                       dont hold my hand its creepy\n",
       "5352        4249.0                           hm what to do what to do\n",
       "5353        2177.0                                         in episode\n",
       "5354        4251.0                         splendid welcome to canada\n",
       "5355        6086.0  welcome to eight days and seven nights of push...\n",
       "\n",
       "[5356 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corpus_creator(cid):\n",
    "    line = '' \n",
    "    for i in dial_df['normalized_text'][dial_df['character_id']==cid]:\n",
    "        line = line + i\n",
    "    return line\n",
    "\n",
    "corpus_df = pd.DataFrame()\n",
    "corpus_df['character_id'] = list(dial_df['character_id'].value_counts().index)\n",
    "\n",
    "temp = []\n",
    "for i in corpus_df['character_id']:\n",
    "    temp.append(corpus_creator(i))\n",
    "\n",
    "corpus_df['normalized_text'] = temp\n",
    "\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Select first 4 characters\n",
    "> choose either 4 or 14 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dial_df = dial_df.loc[dial_df['character_id'].isin(count['id'][:4])]\n",
    "target_names = result['name'][:4]\n",
    "dial_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Select first 14 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_id</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>wheres mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>that life is worth living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>victory party under the slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>mr bergstrom mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>do you know where i could find him</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   character_id                     normalized_text\n",
       "1             9                 wheres mr bergstrom\n",
       "3             9           that life is worth living\n",
       "7             8       victory party under the slide\n",
       "9             9           mr bergstrom mr bergstrom\n",
       "11            9  do you know where i could find him"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset first 14 characters from the original script_df\n",
    "dial_df = dial_df.loc[dial_df['character_id'].isin(count['id'][:14])]\n",
    "target_names = result['name'][:14]\n",
    "dial_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert raw text to TF-IDF vecter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254873\n"
     ]
    }
   ],
   "source": [
    "X = dial_df[\"normalized_text\"]\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2)).fit(X)\n",
    "print(len(vectorizer.vocabulary_))\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "y = dial_df['character_id'].astype(int)\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Benchmark function and training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "    print('_' * 80)\n",
    "    \n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate(target_names):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(\"%s: %s\" % (label, \" \".join(feature_names[top10])))\n",
    "        print()\n",
    "    \n",
    "    print('_' * 80)\n",
    "    print(clf)\n",
    "    print(\"classification report:\")\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    print(metrics.classification_report(y_test, pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Prediction, too bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "train time: 9.281s\n",
      "test time:  0.014s\n",
      "________________________________________________________________________________\n",
      "dimensionality: 254873\n",
      "density: 0.769258\n",
      "top 10 keywords per class:\n",
      "Homer Simpson: house kids artie lisa honey your father my husband husband homer homie\n",
      "Marge Simpson: woo boy beer stupid honey flanders your mother son homer simpson marge\n",
      "Bart Simpson: sir student superintendent students simpson children willie school edna mother\n",
      "Lisa Simpson: carumba man sister krusty im bart cool dad bart simpson milhouse lis\n",
      "C. Montgomery Burns: mr yay dad thats grampa yayyy bart dad you dads dad mom\n",
      "Moe Szyslak: bible well diddly reverend ho boys neighbor lord diddily maude\n",
      "Seymour Skinner: bah my youre fired young plant of fired simpson excellent smithers\n",
      "Ned Flanders: tavern nothin aw here moe uh ah bar ya aint\n",
      "Chief Wiggum: bart look it bart parents my glasses cool my mom my whazzup bart hey bart\n",
      "Milhouse Van Houten: hot diggity diggity war hippo death dead zelda old ya son\n",
      "Krusty the Clown: eddie under arrest simpson crime police arrest ah ralphie boys lou\n",
      "Grampa Simpson: hey simpson my mom him wuss ya poppa crud dingus haw haw haw\n",
      "Nelson Muntz: clown now name kids krusty the my show kid hey hey\n",
      "Lenny Leonard: aw nuts us isotopes nah hes right its secret secret hey hey homer carl\n",
      "\n",
      "________________________________________________________________________________\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "classification report:\n",
      "accuracy:   0.408\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Homer Simpson       0.48      0.30      0.37      3177\n",
      "      Marge Simpson       0.39      0.91      0.54      6964\n",
      "       Bart Simpson       0.64      0.03      0.05       631\n",
      "       Lisa Simpson       0.46      0.18      0.26      3181\n",
      "C. Montgomery Burns       0.48      0.19      0.28      2715\n",
      "        Moe Szyslak       0.53      0.02      0.03       515\n",
      "    Seymour Skinner       0.88      0.11      0.20       744\n",
      "       Ned Flanders       0.53      0.03      0.06       685\n",
      "       Chief Wiggum       1.00      0.00      0.00       444\n",
      "Milhouse Van Houten       1.00      0.00      0.00       418\n",
      "   Krusty the Clown       0.70      0.01      0.03       494\n",
      "     Grampa Simpson       1.00      0.13      0.22       318\n",
      "       Nelson Muntz       0.40      0.01      0.02       447\n",
      "      Lenny Leonard       0.00      0.00      0.00       286\n",
      "\n",
      "        avg / total       0.49      0.41      0.33     21019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h164654156465\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.911s\n",
      "test time:  0.026s\n",
      "________________________________________________________________________________\n",
      "dimensionality: 218705\n",
      "density: 0.215976\n",
      "top 10 keywords per class:\n",
      "Homer Simpson: homer did shoo homer stop oh homie artie homer dont oh homer husband homer homie\n",
      "Marge Simpson: yello moe sweetie lenny stupid woo honey flanders son marge\n",
      "Bart Simpson: good lord adeleine nam johnny detention students edna chalmers superintendent chalmers superintendent\n",
      "Lisa Simpson: bart simpson aye carumba ay carumba hey lis im bart hey dad cool carumba milhouse lis\n",
      "C. Montgomery Burns: bart thats dad dad did oh dad malibu dad im da ad dad thats yayyy mom\n",
      "Moe Szyslak: okily okily dokily doodle hidilly howdilly doodily neighbor maude diddily diddly\n",
      "Seymour Skinner: youre fired ahoy humbug hounds ahoy hoy bobo hoy huzzah excellent smithers\n",
      "Ned Flanders: hey ya harv matter homer barn oh hey tab tavern sorry homer midge aint\n",
      "Chief Wiggum: glasses ravenous playmates playdude playmates umpire battleboat nana seedless whazzup hey bart\n",
      "Milhouse Van Houten: generation breast dead dead jiffy molloy ill jiffy hot diggity diggity zelda matlock\n",
      "Krusty the Clown: uniform crybaby scuzzbag away boys nice work youre arrest arrest eddie ralphie lou\n",
      "Grampa Simpson: twix canola poppa came hey simpson stop hittin hittin crud poppa haw haw haw\n",
      "Nelson Muntz: sponsor baggy teeny ratings krispies rice krispies whats son violin agent comedy\n",
      "Lenny Leonard: wussy nevada eeeeeeeeeeeee ulterior dumbass thank friend hey carl isotopes dental dental plan\n",
      "\n",
      "________________________________________________________________________________\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "classification report:\n",
      "accuracy:   0.397\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Homer Simpson       0.40      0.34      0.37      3253\n",
      "      Marge Simpson       0.43      0.73      0.54      6938\n",
      "       Bart Simpson       0.34      0.13      0.19       631\n",
      "       Lisa Simpson       0.32      0.23      0.27      3114\n",
      "C. Montgomery Burns       0.36      0.29      0.32      2709\n",
      "        Moe Szyslak       0.37      0.13      0.20       522\n",
      "    Seymour Skinner       0.48      0.28      0.36       755\n",
      "       Ned Flanders       0.24      0.08      0.12       687\n",
      "       Chief Wiggum       0.12      0.05      0.07       430\n",
      "Milhouse Van Houten       0.23      0.08      0.12       395\n",
      "   Krusty the Clown       0.27      0.15      0.19       545\n",
      "     Grampa Simpson       0.47      0.16      0.24       309\n",
      "       Nelson Muntz       0.28      0.10      0.14       445\n",
      "      Lenny Leonard       0.13      0.03      0.05       286\n",
      "\n",
      "        avg / total       0.37      0.40      0.36     21019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark(SGDClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Technique[optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h164654156465\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    }
   ],
   "source": [
    "ch2 = SelectPercentile(chi2, percentile=40)\n",
    "X_train = ch2.fit_transform(X_train, y_train)\n",
    "X_test = ch2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "train time: 5.296s\n",
      "test time:  0.010s\n",
      "________________________________________________________________________________\n",
      "dimensionality: 27557\n",
      "density: 0.844831\n",
      "top 10 keywords per class:\n",
      "Homer Simpson: sweetie kids dear ned fathers honey artie husband homer homie\n",
      "Marge Simpson: suckers wife mmmm yello lousy stupid flanders son woo marge\n",
      "Bart Simpson: simpson detention student children school willie superintendent students mother edna\n",
      "Lisa Simpson: awesome man dad bike carumba cool sister krusty milhouse lis\n",
      "C. Montgomery Burns: pony snowball ad yayyy dads bart buddhist malibu dad mom\n",
      "Moe Szyslak: folks christian boys ho diddly lord reverend neighbor maude diddily\n",
      "Seymour Skinner: bobo employee perhaps monty young fired plant simpson excellent smithers\n",
      "Ned Flanders: nothin geez tavern moes whaaa ah talkin bar ya aint\n",
      "Chief Wiggum: station hurry sync nana care whazzup glasses parents cool bart\n",
      "Milhouse Van Houten: abe jiffy hippo dead war ya aint son zelda old\n",
      "Krusty the Clown: bob eddie simpson ah police officer ralphie arrest boys lou\n",
      "Grampa Simpson: lets nelson ya party simpson pound sucks poppa dingus haw\n",
      "Nelson Muntz: laugh kids comedy audience sketch hey clown show cancel kid\n",
      "Lenny Leonard: kinda hes homer isotopes plan secret homers hey dental carl\n",
      "\n",
      "________________________________________________________________________________\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "classification report:\n",
      "accuracy:   0.410\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Homer Simpson       0.44      0.33      0.37      3150\n",
      "      Marge Simpson       0.40      0.87      0.54      6927\n",
      "       Bart Simpson       0.58      0.05      0.09       605\n",
      "       Lisa Simpson       0.42      0.20      0.27      3198\n",
      "C. Montgomery Burns       0.43      0.24      0.31      2716\n",
      "        Moe Szyslak       0.74      0.06      0.11       525\n",
      "    Seymour Skinner       0.79      0.16      0.26       752\n",
      "       Ned Flanders       0.43      0.04      0.08       726\n",
      "       Chief Wiggum       0.50      0.00      0.00       443\n",
      "Milhouse Van Houten       0.50      0.00      0.01       430\n",
      "   Krusty the Clown       0.61      0.07      0.12       483\n",
      "     Grampa Simpson       0.92      0.13      0.23       335\n",
      "       Nelson Muntz       0.33      0.00      0.00       447\n",
      "      Lenny Leonard       0.67      0.01      0.01       282\n",
      "\n",
      "        avg / total       0.46      0.41      0.34     21019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark(LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK preprocessing[optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\h164654156465\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_id</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>wheres mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>that life is worth liv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>victory party under the slid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>mr bergstrom mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>do you know where i could find him</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   character_id                     normalized_text\n",
       "1             9                 wheres mr bergstrom\n",
       "3             9              that life is worth liv\n",
       "7             8        victory party under the slid\n",
       "9             9           mr bergstrom mr bergstrom\n",
       "11            9  do you know where i could find him"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stemmer = SnowballStemmer(language='english', ignore_stopwords=True)\n",
    "dial_nltk_df = dial_df.copy()  # prevent objects changing from each other\n",
    "dial_nltk_df['normalized_text'] = dial_df['normalized_text'].apply(stemmer.stem)\n",
    "dial_nltk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70062,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dial_nltk_df['character_id'].astype(int)\n",
    "X = dial_nltk_df['normalized_text']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224616\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2)).fit(X)\n",
    "print(len(vectorizer.vocabulary_))\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h164654156465\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.300s\n",
      "test time:  0.010s\n",
      "________________________________________________________________________________\n",
      "dimensionality: 167096\n",
      "density: 0.568823\n",
      "top 10 keywords per class:\n",
      "Homer Simpson: marge simpson hom homer dont oh homie oh dear artie husband homi homer homie\n",
      "Marge Simpson: honey wife moe eh stupid flanders boy marg son marge\n",
      "Bart Simpson: radioactive man im bart bart simpson carumba awesom cool whoa milhous milhouse lis\n",
      "Lisa Simpson: dad think buddhist dad did da ad oh dad yay dad mom yayyy dad thats\n",
      "\n",
      "________________________________________________________________________________\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "classification report:\n",
      "accuracy:   0.509\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Homer Simpson       0.56      0.27      0.36      3216\n",
      "Marge Simpson       0.51      0.88      0.65      6865\n",
      " Bart Simpson       0.49      0.18      0.26      3283\n",
      " Lisa Simpson       0.47      0.24      0.32      2665\n",
      "\n",
      "  avg / total       0.51      0.51      0.46     16029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark(SGDClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "train time: 2.607s\n",
      "test time:  0.004s\n",
      "________________________________________________________________________________\n",
      "dimensionality: 167096\n",
      "density: 0.743985\n",
      "top 10 keywords per class:\n",
      "Homer Simpson: house hom ned father going marge simpson husband homi homer homie\n",
      "Marge Simpson: boy moe stupid woo wife flanders homer simpson marg son marge\n",
      "Bart Simpson: man carumba im bart milhous cool krusty whoa bart simpson milhouse lis\n",
      "Lisa Simpson: dad im buddhist bart dad dont mr flanders im lisa yayyy dad thats dad mom\n",
      "\n",
      "________________________________________________________________________________\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "classification report:\n",
      "accuracy:   0.508\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Homer Simpson       0.61      0.24      0.34      3216\n",
      "Marge Simpson       0.49      0.93      0.64      6865\n",
      " Bart Simpson       0.60      0.16      0.25      3283\n",
      " Lisa Simpson       0.52      0.18      0.27      2665\n",
      "\n",
      "  avg / total       0.54      0.51      0.44     16029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark(LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feel so bad, it's a disaster. \n",
    "But wait, we have this ->\n",
    "- https://www.kaggle.com/ambarish/fun-in-text-mining-with-simpsons\n",
    "- https://www.kaggle.com/thebrownviking20/who-said-this-line-eda-classification-keras-ann\n",
    "- https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(objective=\"multi:softmax\", tree_method=\"gpu_exact\", num_class=14, max_depth=7)\n",
    "#random_search = RandomizedSearchCV(xgb, param_distributions=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=7, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, num_class=14, objective='multi:softmax',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1, tree_method='gpu_exact')\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "b'[15:38:54] C:/Users/Administrator/Desktop/xgboost/src/tree/updater_gpu.cu:537: GPU plugin exception: vector<T> too long\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-a59acd78b71a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbenchmark\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-12e1677cc9b3>\u001b[0m in \u001b[0;36mbenchmark\u001b[1;34m(clf)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mtrain_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train time: %0.3fs\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtrain_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set)\u001b[0m\n\u001b[0;32m    545\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1021\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1022\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \"\"\"\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: b'[15:38:54] C:/Users/Administrator/Desktop/xgboost/src/tree/updater_gpu.cu:537: GPU plugin exception: vector<T> too long\\n'"
     ]
    }
   ],
   "source": [
    "benchmark(xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try simple neural network\n",
    "Check if we have gpu support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_id</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>wheres mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>that life is worth living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>victory party under the slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>mr bergstrom mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>do you know where i could find him</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   character_id                     normalized_text\n",
       "1             9                 wheres mr bergstrom\n",
       "3             9           that life is worth living\n",
       "7             8       victory party under the slide\n",
       "9             9           mr bergstrom mr bergstrom\n",
       "11            9  do you know where i could find him"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dial_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dial_df['character_id'].astype(int)\n",
    "X = dial_df['normalized_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27557\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer().fit(X)\n",
    "print(len(vectorizer.vocabulary_))\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70062, 14)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding categorical data using label encoding and one-hot encoding \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "y = onehotencoder.fit_transform(y).toarray()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 27557\n",
    "num_classes = 14\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49043/49043 [==============================] - 26s 539us/step - loss: 2.2222 - acc: 0.2950\n",
      "Epoch 2/10\n",
      "49043/49043 [==============================] - 25s 516us/step - loss: 1.9950 - acc: 0.3404\n",
      "Epoch 3/10\n",
      "49043/49043 [==============================] - 26s 532us/step - loss: 1.7971 - acc: 0.4204\n",
      "Epoch 4/10\n",
      "49043/49043 [==============================] - 26s 540us/step - loss: 1.5998 - acc: 0.4969\n",
      "Epoch 5/10\n",
      "49043/49043 [==============================] - 32s 659us/step - loss: 1.4200 - acc: 0.5591\n",
      "Epoch 6/10\n",
      "49043/49043 [==============================] - 26s 530us/step - loss: 1.2431 - acc: 0.6153\n",
      "Epoch 7/10\n",
      "49043/49043 [==============================] - 25s 518us/step - loss: 1.0896 - acc: 0.6662\n",
      "Epoch 8/10\n",
      "49043/49043 [==============================] - 34s 692us/step - loss: 0.9576 - acc: 0.7047\n",
      "Epoch 9/10\n",
      "49043/49043 [==============================] - 28s 562us/step - loss: 0.8438 - acc: 0.7389\n",
      "Epoch 10/10\n",
      "49043/49043 [==============================] - 26s 521us/step - loss: 0.7558 - acc: 0.7650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d76600d2b0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert features back to each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 4, ..., 3, 1, 7], dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report:\n",
      "accuracy:   0.349\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Homer Simpson       0.36      0.38      0.37      3200\n",
      "      Marge Simpson       0.47      0.54      0.50      7009\n",
      "       Bart Simpson       0.11      0.17      0.13       633\n",
      "       Lisa Simpson       0.29      0.30      0.30      3136\n",
      "C. Montgomery Burns       0.31      0.29      0.30      2637\n",
      "        Moe Szyslak       0.23      0.21      0.22       543\n",
      "    Seymour Skinner       0.34      0.27      0.30       734\n",
      "       Ned Flanders       0.19      0.17      0.18       720\n",
      "       Chief Wiggum       0.07      0.02      0.03       477\n",
      "Milhouse Van Houten       0.07      0.03      0.04       428\n",
      "   Krusty the Clown       0.16      0.07      0.10       494\n",
      "     Grampa Simpson       0.23      0.15      0.18       284\n",
      "       Nelson Muntz       0.06      0.07      0.06       449\n",
      "      Lenny Leonard       0.00      0.00      0.00       275\n",
      "\n",
      "        avg / total       0.33      0.35      0.34     21019\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h164654156465\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"classification report:\")\n",
    "print(\"accuracy:   %0.3f\" % metrics.accuracy_score(y_test, pred))\n",
    "print(metrics.classification_report(y_test, pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\h164654156465\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_id</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>wheres mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>that life is worth liv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>victory party under the slid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>mr bergstrom mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>do you know where i could find him</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   character_id                     normalized_text\n",
       "1             9                 wheres mr bergstrom\n",
       "3             9              that life is worth liv\n",
       "7             8        victory party under the slid\n",
       "9             9           mr bergstrom mr bergstrom\n",
       "11            9  do you know where i could find him"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stemmer = SnowballStemmer(language='english', ignore_stopwords=True)\n",
    "dial_nltk_df = dial_df.copy()  # prevent objects changing from each other\n",
    "dial_nltk_df['normalized_text'] = dial_df['normalized_text'].apply(stemmer.stem)\n",
    "dial_nltk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70062,)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dial_nltk_df['character_id'].astype(int)\n",
    "X = dial_nltk_df['normalized_text']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15046\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=2).fit(X)\n",
    "print(len(vectorizer.vocabulary_))\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46552824, 0.21747984, 2.44835057, 0.4725171 , 0.55126995,\n",
       "       2.79109234, 2.00337413, 2.13681835, 3.38137066, 3.54170458,\n",
       "       3.08534437, 4.89670115, 3.38594626, 5.32386018])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y), y)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding categorical data using label encoding and one-hot encoding \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "y = onehotencoder.fit_transform(y).toarray()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 15046\n",
    "num_classes = 14\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49043/49043 [==============================] - 17s 347us/step - loss: 2.2342 - acc: 0.2946\n",
      "Epoch 2/20\n",
      "49043/49043 [==============================] - 15s 314us/step - loss: 2.0542 - acc: 0.3272\n",
      "Epoch 3/20\n",
      "49043/49043 [==============================] - 16s 325us/step - loss: 1.9827 - acc: 0.3285\n",
      "Epoch 4/20\n",
      "49043/49043 [==============================] - 16s 330us/step - loss: 1.9076 - acc: 0.3259\n",
      "Epoch 5/20\n",
      "49043/49043 [==============================] - 18s 377us/step - loss: 1.8272 - acc: 0.3284\n",
      "Epoch 6/20\n",
      "49043/49043 [==============================] - 16s 330us/step - loss: 1.7531 - acc: 0.3406\n",
      "Epoch 7/20\n",
      "49043/49043 [==============================] - 15s 314us/step - loss: 1.6626 - acc: 0.3743\n",
      "Epoch 8/20\n",
      "49043/49043 [==============================] - 15s 311us/step - loss: 1.5722 - acc: 0.4273\n",
      "Epoch 9/20\n",
      "49043/49043 [==============================] - 15s 309us/step - loss: 1.4892 - acc: 0.4683\n",
      "Epoch 10/20\n",
      "49043/49043 [==============================] - 15s 308us/step - loss: 1.4088 - acc: 0.5098\n",
      "Epoch 11/20\n",
      "49043/49043 [==============================] - 15s 308us/step - loss: 1.3351 - acc: 0.5429\n",
      "Epoch 12/20\n",
      "49043/49043 [==============================] - 15s 308us/step - loss: 1.2834 - acc: 0.5673\n",
      "Epoch 13/20\n",
      "49043/49043 [==============================] - 15s 308us/step - loss: 1.2328 - acc: 0.5893\n",
      "Epoch 14/20\n",
      "49043/49043 [==============================] - 15s 310us/step - loss: 1.1918 - acc: 0.6045\n",
      "Epoch 15/20\n",
      "49043/49043 [==============================] - 17s 343us/step - loss: 1.1604 - acc: 0.6162\n",
      "Epoch 16/20\n",
      "49043/49043 [==============================] - 18s 359us/step - loss: 1.1295 - acc: 0.6267\n",
      "Epoch 17/20\n",
      "49043/49043 [==============================] - 15s 313us/step - loss: 1.1057 - acc: 0.6353\n",
      "Epoch 18/20\n",
      "49043/49043 [==============================] - 15s 313us/step - loss: 1.0803 - acc: 0.6432\n",
      "Epoch 19/20\n",
      "49043/49043 [==============================] - 15s 314us/step - loss: 1.0624 - acc: 0.6510\n",
      "Epoch 20/20\n",
      "49043/49043 [==============================] - 15s 312us/step - loss: 1.0443 - acc: 0.6580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d76cbf6d68>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=1024, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 0, ..., 4, 4, 0], dtype=int64)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report:\n",
      "accuracy:   0.311\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Homer Simpson       0.35      0.36      0.35      3268\n",
      "      Marge Simpson       0.45      0.51      0.48      6871\n",
      "       Bart Simpson       0.04      0.03      0.03       611\n",
      "       Lisa Simpson       0.30      0.24      0.27      3163\n",
      "C. Montgomery Burns       0.29      0.27      0.28      2762\n",
      "        Moe Szyslak       0.22      0.00      0.01       545\n",
      "    Seymour Skinner       0.08      0.41      0.13       769\n",
      "       Ned Flanders       0.04      0.02      0.02       664\n",
      "       Chief Wiggum       0.00      0.00      0.00       453\n",
      "Milhouse Van Houten       0.00      0.00      0.00       417\n",
      "   Krusty the Clown       0.00      0.00      0.00       501\n",
      "     Grampa Simpson       0.00      0.00      0.00       291\n",
      "       Nelson Muntz       0.00      0.00      0.00       404\n",
      "      Lenny Leonard       0.00      0.00      0.00       300\n",
      "\n",
      "        avg / total       0.30      0.31      0.29     21019\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h164654156465\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"classification report:\")\n",
    "print(\"accuracy:   %0.3f\" % metrics.accuracy_score(y_test, pred))\n",
    "print(metrics.classification_report(y_test, pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
