{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who Said the Line in Simpson's TV Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils.extmath import density\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import TC algorithms\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8084: expected 13 fields, saw 20\\nSkipping line 52607: expected 13 fields, saw 21\\nSkipping line 59910: expected 13 fields, saw 21\\n'\n",
      "b'Skipping line 71801: expected 13 fields, saw 20\\nSkipping line 73539: expected 13 fields, saw 21\\nSkipping line 77230: expected 13 fields, saw 21\\nSkipping line 78953: expected 13 fields, saw 21\\nSkipping line 81138: expected 13 fields, saw 20\\nSkipping line 86746: expected 13 fields, saw 22\\nSkipping line 101154: expected 13 fields, saw 21\\nSkipping line 115438: expected 13 fields, saw 20\\nSkipping line 117573: expected 13 fields, saw 22\\nSkipping line 130610: expected 13 fields, saw 22\\n'\n",
      "b'Skipping line 152970: expected 13 fields, saw 22\\nSkipping line 153017: expected 13 fields, saw 20\\nSkipping line 153018: expected 13 fields, saw 30\\nSkipping line 154080: expected 13 fields, saw 20\\nSkipping line 154082: expected 13 fields, saw 20\\nSkipping line 154084: expected 13 fields, saw 20\\nSkipping line 154086: expected 13 fields, saw 20\\nSkipping line 154089: expected 13 fields, saw 23\\nSkipping line 154165: expected 13 fields, saw 21\\nSkipping line 156872: expected 13 fields, saw 20\\n'\n",
      "C:\\Users\\h164654156465\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "script_df = pd.read_csv('simpsons_script_lines.csv', error_bad_lines=False)\n",
    "char_df = pd.read_csv('simpsons_characters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simple Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>number</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>timestamp_in_ms</th>\n",
       "      <th>speaking_line</th>\n",
       "      <th>character_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>raw_location_text</th>\n",
       "      <th>spoken_words</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9549</td>\n",
       "      <td>32</td>\n",
       "      <td>209</td>\n",
       "      <td>Miss Hoover: No, actually, it was a little of ...</td>\n",
       "      <td>848000</td>\n",
       "      <td>True</td>\n",
       "      <td>464</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "      <td>no actually it was a little of both sometimes ...</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9550</td>\n",
       "      <td>32</td>\n",
       "      <td>210</td>\n",
       "      <td>Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?</td>\n",
       "      <td>856000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "      <td>wheres mr bergstrom</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9551</td>\n",
       "      <td>32</td>\n",
       "      <td>211</td>\n",
       "      <td>Miss Hoover: I don't know. Although I'd sure l...</td>\n",
       "      <td>856000</td>\n",
       "      <td>True</td>\n",
       "      <td>464</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "      <td>i dont know although id sure like to talk to h...</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9552</td>\n",
       "      <td>32</td>\n",
       "      <td>212</td>\n",
       "      <td>Lisa Simpson: That life is worth living.</td>\n",
       "      <td>864000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>That life is worth living.</td>\n",
       "      <td>that life is worth living</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9553</td>\n",
       "      <td>32</td>\n",
       "      <td>213</td>\n",
       "      <td>Edna Krabappel-Flanders: The polls will be ope...</td>\n",
       "      <td>864000</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "      <td>the polls will be open from now until the end ...</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  episode_id  number  \\\n",
       "0  9549          32     209   \n",
       "1  9550          32     210   \n",
       "2  9551          32     211   \n",
       "3  9552          32     212   \n",
       "4  9553          32     213   \n",
       "\n",
       "                                            raw_text timestamp_in_ms  \\\n",
       "0  Miss Hoover: No, actually, it was a little of ...          848000   \n",
       "1  Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?          856000   \n",
       "2  Miss Hoover: I don't know. Although I'd sure l...          856000   \n",
       "3           Lisa Simpson: That life is worth living.          864000   \n",
       "4  Edna Krabappel-Flanders: The polls will be ope...          864000   \n",
       "\n",
       "  speaking_line character_id  location_id       raw_character_text  \\\n",
       "0          True          464          3.0              Miss Hoover   \n",
       "1          True            9          3.0             Lisa Simpson   \n",
       "2          True          464          3.0              Miss Hoover   \n",
       "3          True            9          3.0             Lisa Simpson   \n",
       "4          True           40          3.0  Edna Krabappel-Flanders   \n",
       "\n",
       "               raw_location_text  \\\n",
       "0  Springfield Elementary School   \n",
       "1  Springfield Elementary School   \n",
       "2  Springfield Elementary School   \n",
       "3  Springfield Elementary School   \n",
       "4  Springfield Elementary School   \n",
       "\n",
       "                                        spoken_words  \\\n",
       "0  No, actually, it was a little of both. Sometim...   \n",
       "1                             Where's Mr. Bergstrom?   \n",
       "2  I don't know. Although I'd sure like to talk t...   \n",
       "3                         That life is worth living.   \n",
       "4  The polls will be open from now until the end ...   \n",
       "\n",
       "                                     normalized_text  word_count  \n",
       "0  no actually it was a little of both sometimes ...        31.0  \n",
       "1                                wheres mr bergstrom         3.0  \n",
       "2  i dont know although id sure like to talk to h...        22.0  \n",
       "3                          that life is worth living         5.0  \n",
       "4  the polls will be open from now until the end ...        33.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>normalized_name</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Children</td>\n",
       "      <td>children</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>Mechanical Santa</td>\n",
       "      <td>mechanical santa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Tattoo Man</td>\n",
       "      <td>tattoo man</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>DOCTOR ZITSOFSKY</td>\n",
       "      <td>doctor zitsofsky</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>Students</td>\n",
       "      <td>students</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id              name   normalized_name gender\n",
       "0   7          Children          children    NaN\n",
       "1  12  Mechanical Santa  mechanical santa    NaN\n",
       "2  13        Tattoo Man        tattoo man    NaN\n",
       "3  16  DOCTOR ZITSOFSKY  doctor zitsofsky    NaN\n",
       "4  20          Students          students    NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We just need dialogue and character to do text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_id</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>464</td>\n",
       "      <td>no actually it was a little of both sometimes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>wheres mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>464</td>\n",
       "      <td>i dont know although id sure like to talk to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>that life is worth living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>the polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character_id                                    normalized_text\n",
       "0          464  no actually it was a little of both sometimes ...\n",
       "1            9                                wheres mr bergstrom\n",
       "2          464  i dont know although id sure like to talk to h...\n",
       "3            9                          that life is worth living\n",
       "4           40  the polls will be open from now until the end ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dial_df = (\n",
    "    script_df.dropna()\n",
    "    .loc[script_df['speaking_line'] == True]\n",
    "    [['character_id', 'normalized_text']]\n",
    ")\n",
    "dial_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We wanna know the top 14 characters who speaked the most among all the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>23011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>71.0</td>\n",
       "      <td>1622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>139.0</td>\n",
       "      <td>1478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>101.0</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>165.0</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  occurrence\n",
       "0     2.0       23011\n",
       "1     1.0       10750\n",
       "2     8.0       10591\n",
       "3     9.0        9078\n",
       "4    15.0        2498\n",
       "5    17.0        2342\n",
       "6     3.0        2044\n",
       "7    11.0        1793\n",
       "8    71.0        1622\n",
       "9    25.0        1480\n",
       "10  139.0        1478\n",
       "11   31.0        1413\n",
       "12  101.0        1022\n",
       "13  165.0         940"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = dial_df['character_id'].value_counts()\n",
    "count = count.to_frame()\n",
    "count = count.reset_index()\n",
    "count.rename(columns={'index':'id', 'character_id':'occurrence'}, inplace=True)\n",
    "#count['id'] = count['id'].apply(int)\n",
    "count.head(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given the character list in the DS & ML class, we create our own one to compare with it.\n",
    "Here is the list below:\n",
    "1. Homer Simpson\n",
    "2. Marge Simpson\n",
    "3. Bart Simpson\n",
    "4. Lisa Simpson\n",
    "5. C. Montgomery Burns\n",
    "6. Moe Szyslak\n",
    "7. Seymour Skinner\n",
    "8. Ned Flanders\n",
    "9. Grampa Simpson\n",
    "10. Chief Wiggum\n",
    "11. Milhouse Van Houten\n",
    "12. Krusty the Clown\n",
    "13. Nelson Muntz\n",
    "14. Lenny Leonard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>2</td>\n",
       "      <td>Homer Simpson</td>\n",
       "      <td>23011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>Marge Simpson</td>\n",
       "      <td>10750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>Bart Simpson</td>\n",
       "      <td>10591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>9078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5301</th>\n",
       "      <td>15</td>\n",
       "      <td>C. Montgomery Burns</td>\n",
       "      <td>2498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>17</td>\n",
       "      <td>Moe Szyslak</td>\n",
       "      <td>2342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>Seymour Skinner</td>\n",
       "      <td>2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>11</td>\n",
       "      <td>Ned Flanders</td>\n",
       "      <td>1793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>71</td>\n",
       "      <td>Chief Wiggum</td>\n",
       "      <td>1622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>25</td>\n",
       "      <td>Milhouse Van Houten</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>139</td>\n",
       "      <td>Krusty the Clown</td>\n",
       "      <td>1478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>31</td>\n",
       "      <td>Grampa Simpson</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>101</td>\n",
       "      <td>Nelson Muntz</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>165</td>\n",
       "      <td>Lenny Leonard</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                 name  occurrence\n",
       "5300    2        Homer Simpson       23011\n",
       "27      1        Marge Simpson       10750\n",
       "28      8         Bart Simpson       10591\n",
       "29      9         Lisa Simpson        9078\n",
       "5301   15  C. Montgomery Burns        2498\n",
       "30     17          Moe Szyslak        2342\n",
       "31      3      Seymour Skinner        2044\n",
       "32     11         Ned Flanders        1793\n",
       "34     71         Chief Wiggum        1622\n",
       "35     25  Milhouse Van Houten        1480\n",
       "5302  139     Krusty the Clown        1478\n",
       "33     31       Grampa Simpson        1413\n",
       "37    101         Nelson Muntz        1022\n",
       "94    165        Lenny Leonard         940"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.merge(char_df[['id', 'name']], count, on='id')\n",
    "result = result.sort_values('occurrence', ascending=False)\n",
    "result.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_id</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>never thrown a party what about that big bash ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>lisa tell your fatherhomer you are not allowed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>victory party under the slidehey thanks for yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>wheres mr bergstromthat life is worth livingmr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>must turn over got to greet dignitariesabsolut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.0</td>\n",
       "      <td>college boymoes tavern where the elite meet to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>dont worry bart well find something fun for yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.0</td>\n",
       "      <td>hey anybody mind if i serve as bartender you k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>71.0</td>\n",
       "      <td>hellowell its about time somebody reach out to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25.0</td>\n",
       "      <td>uh ohwhat about you bart didnt you votebarts j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>139.0</td>\n",
       "      <td>hi kids youve reached the krusty hotline if yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31.0</td>\n",
       "      <td>huh who whati can dress myselfoh sure last res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>101.0</td>\n",
       "      <td>i didnt vote votings for geekshaw haw hawyeahh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>165.0</td>\n",
       "      <td>whats thathey homer we saved you a doughnuthey...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    character_id                                    normalized_text\n",
       "0            2.0  never thrown a party what about that big bash ...\n",
       "1            1.0  lisa tell your fatherhomer you are not allowed...\n",
       "2            8.0  victory party under the slidehey thanks for yo...\n",
       "3            9.0  wheres mr bergstromthat life is worth livingmr...\n",
       "4           15.0  must turn over got to greet dignitariesabsolut...\n",
       "5           17.0  college boymoes tavern where the elite meet to...\n",
       "6            3.0  dont worry bart well find something fun for yo...\n",
       "7           11.0  hey anybody mind if i serve as bartender you k...\n",
       "8           71.0  hellowell its about time somebody reach out to...\n",
       "9           25.0  uh ohwhat about you bart didnt you votebarts j...\n",
       "10         139.0  hi kids youve reached the krusty hotline if yo...\n",
       "11          31.0  huh who whati can dress myselfoh sure last res...\n",
       "12         101.0  i didnt vote votings for geekshaw haw hawyeahh...\n",
       "13         165.0  whats thathey homer we saved you a doughnuthey..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corpus_creator(cid):\n",
    "    line = '' \n",
    "    for i in dial_df['normalized_text'][dial_df['character_id']==cid]:\n",
    "        line = line + i\n",
    "    return line\n",
    "\n",
    "corpus_df = pd.DataFrame()\n",
    "corpus_df['character_id'] = list(dial_df['character_id'].value_counts().index)\n",
    "\n",
    "temp = []\n",
    "for i in corpus_df['character_id']:\n",
    "    temp.append(corpus_creator(i))\n",
    "\n",
    "corpus_df['normalized_text'] = temp\n",
    "\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Select first 4 characters\n",
    "> choose either 4 or 14 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dial_df = dial_df.loc[dial_df['character_id'].isin(count['id'][:4])]\n",
    "target_names = result['name'][:4]\n",
    "dial_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Select first 14 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_id</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>wheres mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>that life is worth living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>victory party under the slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>mr bergstrom mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>do you know where i could find him</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   character_id                     normalized_text\n",
       "1             9                 wheres mr bergstrom\n",
       "3             9           that life is worth living\n",
       "7             8       victory party under the slide\n",
       "9             9           mr bergstrom mr bergstrom\n",
       "11            9  do you know where i could find him"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset first 14 characters from the original script_df\n",
    "dial_df = dial_df.loc[dial_df['character_id'].isin(count['id'][:14])]\n",
    "target_names = result['name'][:14]\n",
    "dial_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert raw text to TF-IDF vecter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254873\n"
     ]
    }
   ],
   "source": [
    "X = dial_df[\"normalized_text\"]\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2)).fit(X)\n",
    "print(len(vectorizer.vocabulary_))\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "y = dial_df['character_id'].astype(int)\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Benchmark function and training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "    print('_' * 80)\n",
    "    \n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate(target_names):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(\"%s: %s\" % (label, \" \".join(feature_names[top10])))\n",
    "        print()\n",
    "    \n",
    "    print('_' * 80)\n",
    "    print(clf)\n",
    "    print(\"classification report:\")\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    print(metrics.classification_report(y_test, pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Prediction, too bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "train time: 6.523s\n",
      "test time:  0.009s\n",
      "________________________________________________________________________________\n",
      "dimensionality: 101949\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "Homer Simpson: deflate your de corn cheese cubes doodletown either sign imagination can dokes you chosen you charlie bluhdorn checkin\n",
      "Marge Simpson: hug me crony answers answers globe cheese cubes important of booze ill gateway game cheap they deed goes\n",
      "Bart Simpson: as witch glass into be female go thank friend flicka at bed for crime hostile do de believe every\n",
      "Lisa Simpson: as christian civility frito lays bart cheated death get back pains cowell would an undercover didnt hide cyborg\n",
      "C. Montgomery Burns: do those bart son id pay few years id seen class theyre bart ripped an intern dirksen tuck bart cheated\n",
      "Moe Szyslak: and should ho dream changed you be mange dot at first row dancing robot antonio demi be looking\n",
      "Seymour Skinner: dishwasher is in colorful drag racing boogerman dog cmere fabulous medically had were friend flicka billion times frère\n",
      "Ned Flanders: dummy bart bruises best bodyguard am ever dinning seventeen her not about whats an employment hydro electric acceptance speech\n",
      "Chief Wiggum: cause am command respect homework assignments doing laundry back pains gbye burden of dollars give an intern catfish\n",
      "Milhouse Van Houten: america dont im sad city what delivery acceptance speech batten else every in mayday gateway game hydro electric\n",
      "Krusty the Clown: here on brass begonia about whats friend flicka banging fallen out almost done fica antonio darkness falls\n",
      "Grampa Simpson: huzzah ill cells now go dollar call mr everything under family outing be sharps bar next cant expect cant even\n",
      "Nelson Muntz: cowell would catchy em stay grampa being dont pooh dog cmere authority free in could embarrass caught by\n",
      "Lenny Leonard: castrato catholic schools charlie bluhdorn eyes twinkle am invincible catchy be charged be chasing caught her artifacts\n",
      "\n",
      "________________________________________________________________________________\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "classification report:\n",
      "accuracy:   0.408\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Homer Simpson       0.50      0.29      0.37      3201\n",
      "      Marge Simpson       0.38      0.93      0.54      6917\n",
      "       Bart Simpson       0.58      0.02      0.04       606\n",
      "       Lisa Simpson       0.50      0.18      0.26      3181\n",
      "C. Montgomery Burns       0.51      0.19      0.27      2706\n",
      "        Moe Szyslak       0.75      0.01      0.02       511\n",
      "    Seymour Skinner       0.88      0.11      0.19       778\n",
      "       Ned Flanders       0.52      0.02      0.04       728\n",
      "       Chief Wiggum       1.00      0.00      0.00       452\n",
      "Milhouse Van Houten       1.00      0.00      0.00       428\n",
      "   Krusty the Clown       0.75      0.03      0.05       441\n",
      "     Grampa Simpson       0.94      0.10      0.18       321\n",
      "       Nelson Muntz       0.36      0.01      0.02       456\n",
      "      Lenny Leonard       0.75      0.01      0.02       293\n",
      "\n",
      "        avg / total       0.52      0.41      0.32     21019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h164654156465\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.911s\n",
      "test time:  0.026s\n",
      "________________________________________________________________________________\n",
      "dimensionality: 218705\n",
      "density: 0.215976\n",
      "top 10 keywords per class:\n",
      "Homer Simpson: homer did shoo homer stop oh homie artie homer dont oh homer husband homer homie\n",
      "Marge Simpson: yello moe sweetie lenny stupid woo honey flanders son marge\n",
      "Bart Simpson: good lord adeleine nam johnny detention students edna chalmers superintendent chalmers superintendent\n",
      "Lisa Simpson: bart simpson aye carumba ay carumba hey lis im bart hey dad cool carumba milhouse lis\n",
      "C. Montgomery Burns: bart thats dad dad did oh dad malibu dad im da ad dad thats yayyy mom\n",
      "Moe Szyslak: okily okily dokily doodle hidilly howdilly doodily neighbor maude diddily diddly\n",
      "Seymour Skinner: youre fired ahoy humbug hounds ahoy hoy bobo hoy huzzah excellent smithers\n",
      "Ned Flanders: hey ya harv matter homer barn oh hey tab tavern sorry homer midge aint\n",
      "Chief Wiggum: glasses ravenous playmates playdude playmates umpire battleboat nana seedless whazzup hey bart\n",
      "Milhouse Van Houten: generation breast dead dead jiffy molloy ill jiffy hot diggity diggity zelda matlock\n",
      "Krusty the Clown: uniform crybaby scuzzbag away boys nice work youre arrest arrest eddie ralphie lou\n",
      "Grampa Simpson: twix canola poppa came hey simpson stop hittin hittin crud poppa haw haw haw\n",
      "Nelson Muntz: sponsor baggy teeny ratings krispies rice krispies whats son violin agent comedy\n",
      "Lenny Leonard: wussy nevada eeeeeeeeeeeee ulterior dumbass thank friend hey carl isotopes dental dental plan\n",
      "\n",
      "________________________________________________________________________________\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "classification report:\n",
      "accuracy:   0.397\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Homer Simpson       0.40      0.34      0.37      3253\n",
      "      Marge Simpson       0.43      0.73      0.54      6938\n",
      "       Bart Simpson       0.34      0.13      0.19       631\n",
      "       Lisa Simpson       0.32      0.23      0.27      3114\n",
      "C. Montgomery Burns       0.36      0.29      0.32      2709\n",
      "        Moe Szyslak       0.37      0.13      0.20       522\n",
      "    Seymour Skinner       0.48      0.28      0.36       755\n",
      "       Ned Flanders       0.24      0.08      0.12       687\n",
      "       Chief Wiggum       0.12      0.05      0.07       430\n",
      "Milhouse Van Houten       0.23      0.08      0.12       395\n",
      "   Krusty the Clown       0.27      0.15      0.19       545\n",
      "     Grampa Simpson       0.47      0.16      0.24       309\n",
      "       Nelson Muntz       0.28      0.10      0.14       445\n",
      "      Lenny Leonard       0.13      0.03      0.05       286\n",
      "\n",
      "        avg / total       0.37      0.40      0.36     21019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark(SGDClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Technique[optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h164654156465\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    }
   ],
   "source": [
    "ch2 = SelectPercentile(chi2, percentile=40)\n",
    "X_train = ch2.fit_transform(X_train, y_train)\n",
    "X_test = ch2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "train time: 5.296s\n",
      "test time:  0.010s\n",
      "________________________________________________________________________________\n",
      "dimensionality: 27557\n",
      "density: 0.844831\n",
      "top 10 keywords per class:\n",
      "Homer Simpson: sweetie kids dear ned fathers honey artie husband homer homie\n",
      "Marge Simpson: suckers wife mmmm yello lousy stupid flanders son woo marge\n",
      "Bart Simpson: simpson detention student children school willie superintendent students mother edna\n",
      "Lisa Simpson: awesome man dad bike carumba cool sister krusty milhouse lis\n",
      "C. Montgomery Burns: pony snowball ad yayyy dads bart buddhist malibu dad mom\n",
      "Moe Szyslak: folks christian boys ho diddly lord reverend neighbor maude diddily\n",
      "Seymour Skinner: bobo employee perhaps monty young fired plant simpson excellent smithers\n",
      "Ned Flanders: nothin geez tavern moes whaaa ah talkin bar ya aint\n",
      "Chief Wiggum: station hurry sync nana care whazzup glasses parents cool bart\n",
      "Milhouse Van Houten: abe jiffy hippo dead war ya aint son zelda old\n",
      "Krusty the Clown: bob eddie simpson ah police officer ralphie arrest boys lou\n",
      "Grampa Simpson: lets nelson ya party simpson pound sucks poppa dingus haw\n",
      "Nelson Muntz: laugh kids comedy audience sketch hey clown show cancel kid\n",
      "Lenny Leonard: kinda hes homer isotopes plan secret homers hey dental carl\n",
      "\n",
      "________________________________________________________________________________\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "classification report:\n",
      "accuracy:   0.410\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Homer Simpson       0.44      0.33      0.37      3150\n",
      "      Marge Simpson       0.40      0.87      0.54      6927\n",
      "       Bart Simpson       0.58      0.05      0.09       605\n",
      "       Lisa Simpson       0.42      0.20      0.27      3198\n",
      "C. Montgomery Burns       0.43      0.24      0.31      2716\n",
      "        Moe Szyslak       0.74      0.06      0.11       525\n",
      "    Seymour Skinner       0.79      0.16      0.26       752\n",
      "       Ned Flanders       0.43      0.04      0.08       726\n",
      "       Chief Wiggum       0.50      0.00      0.00       443\n",
      "Milhouse Van Houten       0.50      0.00      0.01       430\n",
      "   Krusty the Clown       0.61      0.07      0.12       483\n",
      "     Grampa Simpson       0.92      0.13      0.23       335\n",
      "       Nelson Muntz       0.33      0.00      0.00       447\n",
      "      Lenny Leonard       0.67      0.01      0.01       282\n",
      "\n",
      "        avg / total       0.46      0.41      0.34     21019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark(LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK preprocessing[optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\h164654156465\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_id</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>wheres mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>that life is worth liv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>victory party under the slid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>mr bergstrom mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>do you know where i could find him</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   character_id                     normalized_text\n",
       "1             9                 wheres mr bergstrom\n",
       "3             9              that life is worth liv\n",
       "7             8        victory party under the slid\n",
       "9             9           mr bergstrom mr bergstrom\n",
       "11            9  do you know where i could find him"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stemmer = SnowballStemmer(language='english', ignore_stopwords=True)\n",
    "dial_nltk_df = dial_df.copy()  # prevent objects changing from each other\n",
    "dial_nltk_df['normalized_text'] = dial_df['normalized_text'].apply(stemmer.stem)\n",
    "dial_nltk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70062,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dial_nltk_df['character_id'].astype(int)\n",
    "X = dial_nltk_df['normalized_text']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224616\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2)).fit(X)\n",
    "print(len(vectorizer.vocabulary_))\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h164654156465\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.300s\n",
      "test time:  0.010s\n",
      "________________________________________________________________________________\n",
      "dimensionality: 167096\n",
      "density: 0.568823\n",
      "top 10 keywords per class:\n",
      "Homer Simpson: marge simpson hom homer dont oh homie oh dear artie husband homi homer homie\n",
      "Marge Simpson: honey wife moe eh stupid flanders boy marg son marge\n",
      "Bart Simpson: radioactive man im bart bart simpson carumba awesom cool whoa milhous milhouse lis\n",
      "Lisa Simpson: dad think buddhist dad did da ad oh dad yay dad mom yayyy dad thats\n",
      "\n",
      "________________________________________________________________________________\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "classification report:\n",
      "accuracy:   0.509\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Homer Simpson       0.56      0.27      0.36      3216\n",
      "Marge Simpson       0.51      0.88      0.65      6865\n",
      " Bart Simpson       0.49      0.18      0.26      3283\n",
      " Lisa Simpson       0.47      0.24      0.32      2665\n",
      "\n",
      "  avg / total       0.51      0.51      0.46     16029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark(SGDClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "train time: 2.607s\n",
      "test time:  0.004s\n",
      "________________________________________________________________________________\n",
      "dimensionality: 167096\n",
      "density: 0.743985\n",
      "top 10 keywords per class:\n",
      "Homer Simpson: house hom ned father going marge simpson husband homi homer homie\n",
      "Marge Simpson: boy moe stupid woo wife flanders homer simpson marg son marge\n",
      "Bart Simpson: man carumba im bart milhous cool krusty whoa bart simpson milhouse lis\n",
      "Lisa Simpson: dad im buddhist bart dad dont mr flanders im lisa yayyy dad thats dad mom\n",
      "\n",
      "________________________________________________________________________________\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "classification report:\n",
      "accuracy:   0.508\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Homer Simpson       0.61      0.24      0.34      3216\n",
      "Marge Simpson       0.49      0.93      0.64      6865\n",
      " Bart Simpson       0.60      0.16      0.25      3283\n",
      " Lisa Simpson       0.52      0.18      0.27      2665\n",
      "\n",
      "  avg / total       0.54      0.51      0.44     16029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark(LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feel so bad, it's a disaster. \n",
    "But wait, we have this ->\n",
    "- https://www.kaggle.com/ambarish/fun-in-text-mining-with-simpsons\n",
    "- https://www.kaggle.com/thebrownviking20/who-said-this-line-eda-classification-keras-ann\n",
    "- https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(objective=\"multi:softmax\", tree_method=\"gpu_exact\", num_class=14, max_depth=5, predictor=\"cpu_predictor\")\n",
    "#random_search = RandomizedSearchCV(xgb, param_distributions=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 590.449s\n"
     ]
    }
   ],
   "source": [
    "print(xgb)\n",
    "t0 = time()\n",
    "xgb.fit(X_train, y_train)\n",
    "train_time = time() - t0\n",
    "print(\"train time: %0.3fs\" % train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, num_class=14, objective='multi:softprob',\n",
      "       predictor='cpu_predictor', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=1, tree_method='gpu_exact')\n"
     ]
    }
   ],
   "source": [
    "print(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report:\n",
      "accuracy:   0.400\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Homer Simpson       0.63      0.18      0.28      3201\n",
      "      Marge Simpson       0.37      0.95      0.53      6917\n",
      "       Bart Simpson       0.56      0.09      0.15       606\n",
      "       Lisa Simpson       0.58      0.12      0.20      3181\n",
      "C. Montgomery Burns       0.49      0.17      0.26      2706\n",
      "        Moe Szyslak       0.67      0.08      0.14       511\n",
      "    Seymour Skinner       0.77      0.15      0.25       778\n",
      "       Ned Flanders       0.50      0.07      0.12       728\n",
      "       Chief Wiggum       0.53      0.02      0.04       452\n",
      "Milhouse Van Houten       0.50      0.00      0.01       428\n",
      "   Krusty the Clown       0.66      0.10      0.18       441\n",
      "     Grampa Simpson       0.89      0.10      0.17       321\n",
      "       Nelson Muntz       0.50      0.04      0.07       456\n",
      "      Lenny Leonard       0.44      0.05      0.09       293\n",
      "\n",
      "        avg / total       0.51      0.40      0.31     21019\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h164654156465\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "pred = xgb.predict(X_test)\n",
    "print(\"classification report:\")\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "print(metrics.classification_report(y_test, pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try simple neural network\n",
    "Check if we have gpu support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_id</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>wheres mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>that life is worth living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>victory party under the slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>mr bergstrom mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>do you know where i could find him</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   character_id                     normalized_text\n",
       "1             9                 wheres mr bergstrom\n",
       "3             9           that life is worth living\n",
       "7             8       victory party under the slide\n",
       "9             9           mr bergstrom mr bergstrom\n",
       "11            9  do you know where i could find him"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dial_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dial_df['character_id'].astype(int)\n",
    "X = dial_df['normalized_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27557\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer().fit(X)\n",
    "print(len(vectorizer.vocabulary_))\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70062, 14)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding categorical data using label encoding and one-hot encoding \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "y = onehotencoder.fit_transform(y).toarray()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 27557\n",
    "num_classes = 14\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49043/49043 [==============================] - 26s 539us/step - loss: 2.2222 - acc: 0.2950\n",
      "Epoch 2/10\n",
      "49043/49043 [==============================] - 25s 516us/step - loss: 1.9950 - acc: 0.3404\n",
      "Epoch 3/10\n",
      "49043/49043 [==============================] - 26s 532us/step - loss: 1.7971 - acc: 0.4204\n",
      "Epoch 4/10\n",
      "49043/49043 [==============================] - 26s 540us/step - loss: 1.5998 - acc: 0.4969\n",
      "Epoch 5/10\n",
      "49043/49043 [==============================] - 32s 659us/step - loss: 1.4200 - acc: 0.5591\n",
      "Epoch 6/10\n",
      "49043/49043 [==============================] - 26s 530us/step - loss: 1.2431 - acc: 0.6153\n",
      "Epoch 7/10\n",
      "49043/49043 [==============================] - 25s 518us/step - loss: 1.0896 - acc: 0.6662\n",
      "Epoch 8/10\n",
      "49043/49043 [==============================] - 34s 692us/step - loss: 0.9576 - acc: 0.7047\n",
      "Epoch 9/10\n",
      "49043/49043 [==============================] - 28s 562us/step - loss: 0.8438 - acc: 0.7389\n",
      "Epoch 10/10\n",
      "49043/49043 [==============================] - 26s 521us/step - loss: 0.7558 - acc: 0.7650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d76600d2b0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert features back to each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 4, ..., 3, 1, 7], dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report:\n",
      "accuracy:   0.349\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Homer Simpson       0.36      0.38      0.37      3200\n",
      "      Marge Simpson       0.47      0.54      0.50      7009\n",
      "       Bart Simpson       0.11      0.17      0.13       633\n",
      "       Lisa Simpson       0.29      0.30      0.30      3136\n",
      "C. Montgomery Burns       0.31      0.29      0.30      2637\n",
      "        Moe Szyslak       0.23      0.21      0.22       543\n",
      "    Seymour Skinner       0.34      0.27      0.30       734\n",
      "       Ned Flanders       0.19      0.17      0.18       720\n",
      "       Chief Wiggum       0.07      0.02      0.03       477\n",
      "Milhouse Van Houten       0.07      0.03      0.04       428\n",
      "   Krusty the Clown       0.16      0.07      0.10       494\n",
      "     Grampa Simpson       0.23      0.15      0.18       284\n",
      "       Nelson Muntz       0.06      0.07      0.06       449\n",
      "      Lenny Leonard       0.00      0.00      0.00       275\n",
      "\n",
      "        avg / total       0.33      0.35      0.34     21019\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h164654156465\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"classification report:\")\n",
    "print(\"accuracy:   %0.3f\" % metrics.accuracy_score(y_test, pred))\n",
    "print(metrics.classification_report(y_test, pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\h164654156465\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_id</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>wheres mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>that life is worth liv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>victory party under the slid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>mr bergstrom mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>do you know where i could find him</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   character_id                     normalized_text\n",
       "1             9                 wheres mr bergstrom\n",
       "3             9              that life is worth liv\n",
       "7             8        victory party under the slid\n",
       "9             9           mr bergstrom mr bergstrom\n",
       "11            9  do you know where i could find him"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stemmer = SnowballStemmer(language='english', ignore_stopwords=True)\n",
    "dial_nltk_df = dial_df.copy()  # prevent objects changing from each other\n",
    "dial_nltk_df['normalized_text'] = dial_df['normalized_text'].apply(stemmer.stem)\n",
    "dial_nltk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70062,)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dial_nltk_df['character_id'].astype(int)\n",
    "X = dial_nltk_df['normalized_text']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15046\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=2).fit(X)\n",
    "print(len(vectorizer.vocabulary_))\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46552824, 0.21747984, 2.44835057, 0.4725171 , 0.55126995,\n",
       "       2.79109234, 2.00337413, 2.13681835, 3.38137066, 3.54170458,\n",
       "       3.08534437, 4.89670115, 3.38594626, 5.32386018])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y), y)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding categorical data using label encoding and one-hot encoding \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "y = onehotencoder.fit_transform(y).toarray()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 15046\n",
    "num_classes = 14\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49043/49043 [==============================] - 17s 347us/step - loss: 2.2342 - acc: 0.2946\n",
      "Epoch 2/20\n",
      "49043/49043 [==============================] - 15s 314us/step - loss: 2.0542 - acc: 0.3272\n",
      "Epoch 3/20\n",
      "49043/49043 [==============================] - 16s 325us/step - loss: 1.9827 - acc: 0.3285\n",
      "Epoch 4/20\n",
      "49043/49043 [==============================] - 16s 330us/step - loss: 1.9076 - acc: 0.3259\n",
      "Epoch 5/20\n",
      "49043/49043 [==============================] - 18s 377us/step - loss: 1.8272 - acc: 0.3284\n",
      "Epoch 6/20\n",
      "49043/49043 [==============================] - 16s 330us/step - loss: 1.7531 - acc: 0.3406\n",
      "Epoch 7/20\n",
      "49043/49043 [==============================] - 15s 314us/step - loss: 1.6626 - acc: 0.3743\n",
      "Epoch 8/20\n",
      "49043/49043 [==============================] - 15s 311us/step - loss: 1.5722 - acc: 0.4273\n",
      "Epoch 9/20\n",
      "49043/49043 [==============================] - 15s 309us/step - loss: 1.4892 - acc: 0.4683\n",
      "Epoch 10/20\n",
      "49043/49043 [==============================] - 15s 308us/step - loss: 1.4088 - acc: 0.5098\n",
      "Epoch 11/20\n",
      "49043/49043 [==============================] - 15s 308us/step - loss: 1.3351 - acc: 0.5429\n",
      "Epoch 12/20\n",
      "49043/49043 [==============================] - 15s 308us/step - loss: 1.2834 - acc: 0.5673\n",
      "Epoch 13/20\n",
      "49043/49043 [==============================] - 15s 308us/step - loss: 1.2328 - acc: 0.5893\n",
      "Epoch 14/20\n",
      "49043/49043 [==============================] - 15s 310us/step - loss: 1.1918 - acc: 0.6045\n",
      "Epoch 15/20\n",
      "49043/49043 [==============================] - 17s 343us/step - loss: 1.1604 - acc: 0.6162\n",
      "Epoch 16/20\n",
      "49043/49043 [==============================] - 18s 359us/step - loss: 1.1295 - acc: 0.6267\n",
      "Epoch 17/20\n",
      "49043/49043 [==============================] - 15s 313us/step - loss: 1.1057 - acc: 0.6353\n",
      "Epoch 18/20\n",
      "49043/49043 [==============================] - 15s 313us/step - loss: 1.0803 - acc: 0.6432\n",
      "Epoch 19/20\n",
      "49043/49043 [==============================] - 15s 314us/step - loss: 1.0624 - acc: 0.6510\n",
      "Epoch 20/20\n",
      "49043/49043 [==============================] - 15s 312us/step - loss: 1.0443 - acc: 0.6580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d76cbf6d68>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=1024, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 0, ..., 4, 4, 0], dtype=int64)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report:\n",
      "accuracy:   0.311\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Homer Simpson       0.35      0.36      0.35      3268\n",
      "      Marge Simpson       0.45      0.51      0.48      6871\n",
      "       Bart Simpson       0.04      0.03      0.03       611\n",
      "       Lisa Simpson       0.30      0.24      0.27      3163\n",
      "C. Montgomery Burns       0.29      0.27      0.28      2762\n",
      "        Moe Szyslak       0.22      0.00      0.01       545\n",
      "    Seymour Skinner       0.08      0.41      0.13       769\n",
      "       Ned Flanders       0.04      0.02      0.02       664\n",
      "       Chief Wiggum       0.00      0.00      0.00       453\n",
      "Milhouse Van Houten       0.00      0.00      0.00       417\n",
      "   Krusty the Clown       0.00      0.00      0.00       501\n",
      "     Grampa Simpson       0.00      0.00      0.00       291\n",
      "       Nelson Muntz       0.00      0.00      0.00       404\n",
      "      Lenny Leonard       0.00      0.00      0.00       300\n",
      "\n",
      "        avg / total       0.30      0.31      0.29     21019\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h164654156465\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"classification report:\")\n",
    "print(\"accuracy:   %0.3f\" % metrics.accuracy_score(y_test, pred))\n",
    "print(metrics.classification_report(y_test, pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
